{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnosing seq_1hot encoding issues in: PDB-GO/PDB_GO_train_00-of-30.tfrecords\n",
      "\n",
      "============================================================\n",
      "DIAGNOSTIC FOR PROTEIN 1\n",
      "============================================================\n",
      "Protein ID: 2ZPA-A\n",
      "L (sequence length): 671\n",
      "seq_1hot total values: 17446\n",
      "\n",
      "Detailed analysis of first 50 positions:\n",
      "Pos | Values Sum | Max Val | Has 1.0 | AA | Raw Values (first 5)\n",
      "--------------------------------------------------------------------------------\n",
      "  1 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "  2 |        1.0 |     1.0 |       1 | Q    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "  3 |        1.0 |     1.0 |       1 | G    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "  4 |        1.0 |     1.0 |       1 | I    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "  5 |        1.0 |     1.0 |       1 | N    | ['0.0', '0.0', '1.0', '0.0', '0.0']\n",
      "  6 |        1.0 |     1.0 |       1 | L    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "  7 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "  8 |        1.0 |     1.0 |       1 | K    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "  9 |        1.0 |     1.0 |       1 | A    | ['1.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 10 |        1.0 |     1.0 |       1 | L    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 11 |        1.0 |     1.0 |       1 | P    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 12 |        1.0 |     1.0 |       1 | Y    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 13 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 14 |        1.0 |     1.0 |       1 | E    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 15 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 16 |        1.0 |     1.0 |       1 | G    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 17 |        1.0 |     1.0 |       1 | M    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 18 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 19 |        2.0 |     1.0 |       1 | MULTI(2) | ['0.0', '0.0', '0.0', '1.0', '0.0']\n",
      " 20 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 21 |        1.0 |     1.0 |       1 | P    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 22 |        1.0 |     1.0 |       1 | F    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 23 |        1.0 |     1.0 |       1 | C    | ['0.0', '0.0', '0.0', '0.0', '1.0']\n",
      " 24 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 25 |        1.0 |     1.0 |       1 | C    | ['0.0', '0.0', '0.0', '0.0', '1.0']\n",
      " 26 |        1.0 |     1.0 |       1 | Y    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 27 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 28 |        2.0 |     1.0 |       1 | MULTI(2) | ['0.0', '0.0', '0.0', '0.0', '1.0']\n",
      " 29 |        1.0 |     1.0 |       1 | T    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 30 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 31 |        1.0 |     1.0 |       1 | K    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 32 |        1.0 |     1.0 |       1 | H    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 33 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 34 |        2.0 |     1.0 |       1 | MULTI(2) | ['0.0', '0.0', '0.0', '0.0', '1.0']\n",
      " 35 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 36 |        1.0 |     1.0 |       1 | V    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 37 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 38 |        2.0 |     1.0 |       1 | MULTI(2) | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 39 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 40 |        1.0 |     1.0 |       1 | L    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 41 |        1.0 |     1.0 |       1 | W    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 42 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 43 |        1.0 |     1.0 |       1 | L    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 44 |        1.0 |     1.0 |       1 | S    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 45 |        1.0 |     1.0 |       1 | M    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 46 |        1.0 |     1.0 |       1 | T    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 47 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 48 |        1.0 |     1.0 |       1 | A    | ['1.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 49 |        1.0 |     1.0 |       1 | I    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 50 |        1.0 |     1.0 |       1 | M    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "\n",
      "Summary for first 50 positions:\n",
      "  - Valid amino acid positions: 31\n",
      "  - Zero positions (no amino acid): 15\n",
      "  - Multi-1.0 positions: 4\n",
      "\n",
      "Checking for encoding patterns:\n",
      "  - Unique values in seq_1hot: [0.0, 1.0]\n",
      "  - Total 1.0 values: 671\n",
      "  - Expected (L): 671\n",
      "  - Ratio: 1.000\n",
      "\n",
      "Distribution of 1.0s per position:\n",
      "  - 0 ones: 269 positions\n",
      "  - 1 ones: 535 positions\n",
      "  - 2 ones: 68 positions\n",
      "\n",
      "Checking for potential indexing issues:\n",
      "  - First valid amino acid at position: 2\n",
      "\n",
      "Testing different interpretations:\n",
      "  - Valid amino acids in positions 1-20 (0-indexed): 14\n",
      "\n",
      "============================================================\n",
      "DIAGNOSTIC FOR PROTEIN 2\n",
      "============================================================\n",
      "Protein ID: 2GBB-A\n",
      "L (sequence length): 156\n",
      "seq_1hot total values: 4056\n",
      "\n",
      "Detailed analysis of first 50 positions:\n",
      "Pos | Values Sum | Max Val | Has 1.0 | AA | Raw Values (first 5)\n",
      "--------------------------------------------------------------------------------\n",
      "  1 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "  2 |        1.0 |     1.0 |       1 | A    | ['1.0', '0.0', '0.0', '0.0', '0.0']\n",
      "  3 |        1.0 |     1.0 |       1 | E    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "  4 |        1.0 |     1.0 |       1 | D    | ['0.0', '0.0', '0.0', '1.0', '0.0']\n",
      "  5 |        1.0 |     1.0 |       1 | A    | ['1.0', '0.0', '0.0', '0.0', '0.0']\n",
      "  6 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "  7 |        2.0 |     1.0 |       1 | MULTI(2) | ['0.0', '0.0', '0.0', '0.0', '1.0']\n",
      "  8 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "  9 |        1.0 |     1.0 |       1 | W    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 10 |        1.0 |     1.0 |       1 | P    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 11 |        1.0 |     1.0 |       1 | M    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 12 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 13 |        1.0 |     1.0 |       1 | L    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 14 |        1.0 |     1.0 |       1 | Q    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 15 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 16 |        1.0 |     1.0 |       1 | D    | ['0.0', '0.0', '0.0', '1.0', '0.0']\n",
      " 17 |        1.0 |     1.0 |       1 | T    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 18 |        1.0 |     1.0 |       1 | N    | ['0.0', '0.0', '1.0', '0.0', '0.0']\n",
      " 19 |        1.0 |     1.0 |       1 | Y    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 20 |        1.0 |     1.0 |       1 | V    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 21 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 22 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 23 |        2.0 |     1.0 |       1 | MULTI(2) | ['0.0', '1.0', '0.0', '0.0', '0.0']\n",
      " 24 |        1.0 |     1.0 |       1 | I    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 25 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 26 |        1.0 |     1.0 |       1 | G    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 27 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 28 |        2.0 |     1.0 |       1 | MULTI(2) | ['0.0', '1.0', '0.0', '0.0', '0.0']\n",
      " 29 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 30 |        1.0 |     1.0 |       1 | R    | ['0.0', '1.0', '0.0', '0.0', '0.0']\n",
      " 31 |        1.0 |     1.0 |       1 | Q    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 32 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 33 |        1.0 |     1.0 |       1 | Q    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 34 |        1.0 |     1.0 |       1 | G    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 35 |        1.0 |     1.0 |       1 | R    | ['0.0', '1.0', '0.0', '0.0', '0.0']\n",
      " 36 |        1.0 |     1.0 |       1 | L    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 37 |        1.0 |     1.0 |       1 | M    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 38 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 39 |        1.0 |     1.0 |       1 | E    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 40 |        1.0 |     1.0 |       1 | T    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 41 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 42 |        2.0 |     1.0 |       1 | MULTI(2) | ['0.0', '0.0', '0.0', '1.0', '0.0']\n",
      " 43 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 44 |        0.0 |     0.0 |       0 | NONE | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 45 |        1.0 |     1.0 |       1 | N    | ['0.0', '0.0', '1.0', '0.0', '0.0']\n",
      " 46 |        1.0 |     1.0 |       1 | A    | ['1.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 47 |        1.0 |     1.0 |       1 | L    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 48 |        1.0 |     1.0 |       1 | F    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 49 |        1.0 |     1.0 |       1 | V    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      " 50 |        1.0 |     1.0 |       1 | S    | ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
      "\n",
      "Summary for first 50 positions:\n",
      "  - Valid amino acid positions: 31\n",
      "  - Zero positions (no amino acid): 15\n",
      "  - Multi-1.0 positions: 4\n",
      "\n",
      "Checking for encoding patterns:\n",
      "  - Unique values in seq_1hot: [0.0, 1.0]\n",
      "  - Total 1.0 values: 156\n",
      "  - Expected (L): 156\n",
      "  - Ratio: 1.000\n",
      "\n",
      "Distribution of 1.0s per position:\n",
      "  - 0 ones: 57 positions\n",
      "  - 1 ones: 134 positions\n",
      "  - 2 ones: 11 positions\n",
      "\n",
      "Checking for potential indexing issues:\n",
      "  - First valid amino acid at position: 2\n",
      "\n",
      "Testing different interpretations:\n",
      "  - Valid amino acids in positions 1-20 (0-indexed): 14\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def diagnose_seq_encoding_issues(file_path, num_examples=2):\n",
    "    \"\"\"\n",
    "    Diagnoses issues with seq_1hot encoding to understand why there are so many unknowns.\n",
    "    \"\"\"\n",
    "    print(f\"Diagnosing seq_1hot encoding issues in: {file_path}\")\n",
    "    dataset = tf.data.TFRecordDataset(file_path)\n",
    "    \n",
    "    amino_acids = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', \n",
    "                   'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
    "    \n",
    "    for i, raw_record in enumerate(dataset.take(num_examples)):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"DIAGNOSTIC FOR PROTEIN {i+1}\")\n",
    "        print('='*60)\n",
    "        \n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "        \n",
    "        prot_id = example.features.feature['prot_id'].bytes_list.value[0].decode('utf-8')\n",
    "        L_value = list(example.features.feature['L'].int64_list.value)[0]\n",
    "        seq_1hot = list(example.features.feature['seq_1hot'].float_list.value)\n",
    "        \n",
    "        print(f\"Protein ID: {prot_id}\")\n",
    "        print(f\"L (sequence length): {L_value}\")\n",
    "        print(f\"seq_1hot total values: {len(seq_1hot)}\")\n",
    "        \n",
    "        # Check the first 50 positions in detail\n",
    "        print(f\"\\nDetailed analysis of first 50 positions:\")\n",
    "        print(\"Pos | Values Sum | Max Val | Has 1.0 | AA | Raw Values (first 5)\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        valid_positions = 0\n",
    "        zero_positions = 0\n",
    "        multi_one_positions = 0\n",
    "        \n",
    "        for pos in range(min(50, len(seq_1hot) // 20)):\n",
    "            start_idx = pos * 20\n",
    "            end_idx = start_idx + 20\n",
    "            pos_values = seq_1hot[start_idx:end_idx]\n",
    "            \n",
    "            # Statistics for this position\n",
    "            values_sum = sum(pos_values)\n",
    "            max_val = max(pos_values)\n",
    "            ones_count = sum(1 for v in pos_values if v == 1.0)\n",
    "            has_one = ones_count > 0\n",
    "            \n",
    "            # Determine amino acid\n",
    "            if ones_count == 1:\n",
    "                aa_idx = pos_values.index(1.0)\n",
    "                aa = amino_acids[aa_idx]\n",
    "                valid_positions += 1\n",
    "            elif ones_count == 0:\n",
    "                aa = \"NONE\"\n",
    "                zero_positions += 1\n",
    "            else:\n",
    "                aa = f\"MULTI({ones_count})\"\n",
    "                multi_one_positions += 1\n",
    "            \n",
    "            # Show first 5 values for inspection\n",
    "            first_5 = [f\"{v:.1f}\" for v in pos_values[:5]]\n",
    "            \n",
    "            print(f\"{pos+1:3d} | {values_sum:10.1f} | {max_val:7.1f} | {has_one:7} | {aa:4s} | {first_5}\")\n",
    "        \n",
    "        print(f\"\\nSummary for first 50 positions:\")\n",
    "        print(f\"  - Valid amino acid positions: {valid_positions}\")\n",
    "        print(f\"  - Zero positions (no amino acid): {zero_positions}\")\n",
    "        print(f\"  - Multi-1.0 positions: {multi_one_positions}\")\n",
    "        \n",
    "        # Check if there's a pattern in the encoding\n",
    "        print(f\"\\nChecking for encoding patterns:\")\n",
    "        \n",
    "        # Look for non-standard values\n",
    "        unique_values = set(seq_1hot)\n",
    "        print(f\"  - Unique values in seq_1hot: {sorted(unique_values)}\")\n",
    "        \n",
    "        # Check if values are exactly 0.0 and 1.0\n",
    "        non_binary = [v for v in seq_1hot if v != 0.0 and v != 1.0]\n",
    "        if non_binary:\n",
    "            print(f\"  - Non-binary values found: {len(non_binary)} values\")\n",
    "            print(f\"  - Sample non-binary values: {non_binary[:10]}\")\n",
    "        \n",
    "        # Check the total number of 1.0s across all positions\n",
    "        total_ones = sum(1 for v in seq_1hot if v == 1.0)\n",
    "        print(f\"  - Total 1.0 values: {total_ones}\")\n",
    "        print(f\"  - Expected (L): {L_value}\")\n",
    "        print(f\"  - Ratio: {total_ones/L_value:.3f}\")\n",
    "        \n",
    "        # Look at the distribution of 1.0s across positions\n",
    "        ones_per_position = []\n",
    "        for pos in range(len(seq_1hot) // 20):\n",
    "            start_idx = pos * 20\n",
    "            end_idx = start_idx + 20\n",
    "            pos_values = seq_1hot[start_idx:end_idx]\n",
    "            ones_count = sum(1 for v in pos_values if v == 1.0)\n",
    "            ones_per_position.append(ones_count)\n",
    "        \n",
    "        # Count positions by number of 1.0s\n",
    "        from collections import Counter\n",
    "        ones_distribution = Counter(ones_per_position)\n",
    "        print(f\"\\nDistribution of 1.0s per position:\")\n",
    "        for num_ones, count in sorted(ones_distribution.items()):\n",
    "            print(f\"  - {num_ones} ones: {count} positions\")\n",
    "        \n",
    "        # Check if there's an offset or different indexing\n",
    "        print(f\"\\nChecking for potential indexing issues:\")\n",
    "        \n",
    "        # Look for the first valid amino acid\n",
    "        first_valid_pos = None\n",
    "        for pos in range(min(20, len(seq_1hot) // 20)):\n",
    "            start_idx = pos * 20\n",
    "            end_idx = start_idx + 20\n",
    "            pos_values = seq_1hot[start_idx:end_idx]\n",
    "            if sum(1 for v in pos_values if v == 1.0) == 1:\n",
    "                first_valid_pos = pos\n",
    "                break\n",
    "        \n",
    "        if first_valid_pos is not None:\n",
    "            print(f\"  - First valid amino acid at position: {first_valid_pos + 1}\")\n",
    "        else:\n",
    "            print(f\"  - No valid amino acids found in first 20 positions!\")\n",
    "        \n",
    "        # Check if the sequence might be 0-indexed vs 1-indexed\n",
    "        print(f\"\\nTesting different interpretations:\")\n",
    "        \n",
    "        # Try interpreting as 0-indexed (skip position 0)\n",
    "        valid_from_pos_0 = 0\n",
    "        for pos in range(1, min(21, len(seq_1hot) // 20)):\n",
    "            start_idx = pos * 20\n",
    "            end_idx = start_idx + 20\n",
    "            pos_values = seq_1hot[start_idx:end_idx]\n",
    "            if sum(1 for v in pos_values if v == 1.0) == 1:\n",
    "                valid_from_pos_0 += 1\n",
    "        \n",
    "        print(f\"  - Valid amino acids in positions 1-20 (0-indexed): {valid_from_pos_0}\")\n",
    "\n",
    "# Run the diagnostic\n",
    "train_file = \"PDB-GO/PDB_GO_train_00-of-30.tfrecords\"\n",
    "diagnose_seq_encoding_issues(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting file: PDB-GO/PDB_GO_train_00-of-30.tfrecords\n",
      "\n",
      "Protein 1:\n",
      "Protein ID: 2ZPA-A\n",
      "\n",
      "Feature shapes:\n",
      "  - ca_dist_matrix: float, shape=450241\n",
      "  - bp_labels: int64, shape=1943\n",
      "  - mf_labels: int64, shape=489\n",
      "  - cb_dist_matrix: float, shape=450241\n",
      "  - seq_1hot: float, shape=17446\n",
      "  - L: int64, shape=1\n",
      "  - prot_id: bytes, shape=1\n",
      "  - cc_labels: int64, shape=320\n",
      "\n",
      "Label analysis:\n",
      "\n",
      "Cellular Component (cc_labels):\n",
      "  - Total labels: 320\n",
      "  - Active labels (value=1): 0\n",
      "\n",
      "Molecular Function (mf_labels):\n",
      "  - Total labels: 489\n",
      "  - Active labels (value=1): 15\n",
      "  - Active indices: [9, 68, 74, 88, 98, 114, 183, 205, 253, 270, 337, 339, 463, 482, 488]\n",
      "\n",
      "Biological Process (bp_labels):\n",
      "  - Total labels: 1943\n",
      "  - Active labels (value=1): 10\n",
      "  - Active indices: [46, 136, 192, 273, 322, 623, 637, 781, 1221, 1417]\n",
      "\n",
      "Protein 2:\n",
      "Protein ID: 2GBB-A\n",
      "\n",
      "Feature shapes:\n",
      "  - ca_dist_matrix: float, shape=24336\n",
      "  - L: int64, shape=1\n",
      "  - mf_labels: int64, shape=489\n",
      "  - prot_id: bytes, shape=1\n",
      "  - cc_labels: int64, shape=320\n",
      "  - cb_dist_matrix: float, shape=24336\n",
      "  - bp_labels: int64, shape=1943\n",
      "  - seq_1hot: float, shape=4056\n",
      "\n",
      "Label analysis:\n",
      "\n",
      "Cellular Component (cc_labels):\n",
      "  - Total labels: 320\n",
      "  - Active labels (value=1): 1\n",
      "  - Active indices: [81]\n",
      "\n",
      "Molecular Function (mf_labels):\n",
      "  - Total labels: 489\n",
      "  - Active labels (value=1): 2\n",
      "  - Active indices: [250, 432]\n",
      "\n",
      "Biological Process (bp_labels):\n",
      "  - Total labels: 1943\n",
      "  - Active labels (value=1): 15\n",
      "  - Active indices: [18, 155, 313, 314, 370, 546, 744, 792, 934, 1203, 1319, 1707, 1732, 1744, 1871]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def inspect_protein_labels(file_path, num_examples=2):\n",
    "    \"\"\"\n",
    "    Inspects a protein record and its labels from a TFRecord file.\n",
    "    For each label type (cc, mf, bp), identifies which positions have a value of 1.\n",
    "    \"\"\"\n",
    "    print(f\"Inspecting file: {file_path}\")\n",
    "    dataset = tf.data.TFRecordDataset(file_path)\n",
    "    \n",
    "    for i, raw_record in enumerate(dataset.take(num_examples)):\n",
    "        print(f\"\\nProtein {i+1}:\")\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "        \n",
    "        # Get protein ID\n",
    "        prot_id = example.features.feature['prot_id'].bytes_list.value[0].decode('utf-8')\n",
    "        print(f\"Protein ID: {prot_id}\")\n",
    "        \n",
    "        # Print shape information for all features\n",
    "        print(\"\\nFeature shapes:\")\n",
    "        for key in example.features.feature:\n",
    "            feature = example.features.feature[key]\n",
    "            \n",
    "            if feature.HasField('bytes_list'):\n",
    "                shape = len(feature.bytes_list.value)\n",
    "                dtype = \"bytes\"\n",
    "            elif feature.HasField('float_list'):\n",
    "                shape = len(feature.float_list.value)\n",
    "                dtype = \"float\"\n",
    "            elif feature.HasField('int64_list'):\n",
    "                shape = len(feature.int64_list.value)\n",
    "                dtype = \"int64\"\n",
    "            \n",
    "            print(f\"  - {key}: {dtype}, shape={shape}\")\n",
    "        \n",
    "        # Extract and analyze label features\n",
    "        label_types = {\n",
    "            'cc_labels': 'Cellular Component',\n",
    "            'mf_labels': 'Molecular Function',\n",
    "            'bp_labels': 'Biological Process'\n",
    "        }\n",
    "        \n",
    "        print(\"\\nLabel analysis:\")\n",
    "        for label_key, label_name in label_types.items():\n",
    "            if label_key in example.features.feature:\n",
    "                labels = list(example.features.feature[label_key].int64_list.value)\n",
    "                active_indices = [i for i, val in enumerate(labels) if val == 1]\n",
    "                \n",
    "                print(f\"\\n{label_name} ({label_key}):\")\n",
    "                print(f\"  - Total labels: {len(labels)}\")\n",
    "                print(f\"  - Active labels (value=1): {len(active_indices)}\")\n",
    "                if len(active_indices) > 0:\n",
    "                    print(f\"  - Active indices: {active_indices}\")\n",
    "                    \n",
    "        # Examine sequence one-hot encoding if available\n",
    "        if 'seq_1hot' in example.features.feature:\n",
    "            seq_1hot = list(example.features.feature['seq_1hot'].float_list.value)\n",
    "            seq_length = len(seq_1hot) // 20  # Assuming 20 amino acids\n",
    "            \n",
    "            if seq_length * 20 == len(seq_1hot):\n",
    "                print(f\"\\nSequence one-hot encoding:\")\n",
    "                print(f\"  - Sequence length: {seq_length}\")\n",
    "                print(f\"  - Total one-hot values: {len(seq_1hot)}\")\n",
    "                \n",
    "                # Extract a small sample of the sequence (first 5 positions)\n",
    "                if seq_length >= 5:\n",
    "                    print(\"  - First 5 positions (20 amino acids per position):\")\n",
    "                    for pos in range(5):\n",
    "                        pos_values = seq_1hot[pos*20:(pos+1)*20]\n",
    "                        if 1.0 in pos_values:\n",
    "                            aa_index = pos_values.index(1.0)\n",
    "                            print(f\"    Position {pos+1}: 1.0 at index {aa_index}\")\n",
    "                        else:\n",
    "                            print(f\"    Position {pos+1}: No 1.0 value found\")\n",
    "\n",
    "# Use proper file path with forward slashes\n",
    "train_file = \"PDB-GO/PDB_GO_train_00-of-30.tfrecords\"\n",
    "inspect_protein_labels(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting file: PDB-GO/PDB_GO_train_00-of-30.tfrecords\n",
      "\n",
      "==================================================\n",
      "Protein 1:\n",
      "Protein ID: 2ZPA-A\n",
      "\n",
      "L (sequence length): 671\n",
      "\n",
      "seq_1hot analysis:\n",
      "  - Total values in seq_1hot: 17446\n",
      "  - Calculated sequence length: 872\n",
      "  - Expected total (seq_length * 20): 17440\n",
      "\n",
      "First 10 amino acid positions:\n",
      "  Position 1: No amino acid found (all zeros)\n",
      "  Position 2: Q (index 5)\n",
      "  Position 3: G (index 7)\n",
      "  Position 4: I (index 9)\n",
      "  Position 5: N (index 2)\n",
      "  Position 6: L (index 10)\n",
      "  Position 7: No amino acid found (all zeros)\n",
      "  Position 8: K (index 11)\n",
      "  Position 9: A (index 0)\n",
      "  Position 10: L (index 10)\n",
      "\n",
      "seq_1hot statistics:\n",
      "  - Total 1.0 values: 671\n",
      "  - Total 0.0 values: 16775\n",
      "  - Other values: 0\n",
      "\n",
      "Raw seq_1hot values (first 40 = first 2 positions):\n",
      "  Position 1: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "  Position 2: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "==================================================\n",
      "Protein 2:\n",
      "Protein ID: 2GBB-A\n",
      "\n",
      "L (sequence length): 156\n",
      "\n",
      "seq_1hot analysis:\n",
      "  - Total values in seq_1hot: 4056\n",
      "  - Calculated sequence length: 202\n",
      "  - Expected total (seq_length * 20): 4040\n",
      "\n",
      "First 10 amino acid positions:\n",
      "  Position 1: No amino acid found (all zeros)\n",
      "  Position 2: A (index 0)\n",
      "  Position 3: E (index 6)\n",
      "  Position 4: D (index 3)\n",
      "  Position 5: A (index 0)\n",
      "  Position 6: No amino acid found (all zeros)\n",
      "  Position 7: C (index 4)\n",
      "  Position 8: No amino acid found (all zeros)\n",
      "  Position 9: W (index 17)\n",
      "  Position 10: P (index 14)\n",
      "\n",
      "seq_1hot statistics:\n",
      "  - Total 1.0 values: 156\n",
      "  - Total 0.0 values: 3900\n",
      "  - Other values: 0\n",
      "\n",
      "Raw seq_1hot values (first 40 = first 2 positions):\n",
      "  Position 1: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "  Position 2: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def inspect_seq_and_L_values(file_path, num_examples=2):\n",
    "    \"\"\"\n",
    "    Inspects seq_1hot and L values from a TFRecord file.\n",
    "    Prints the actual values for L and detailed seq_1hot information.\n",
    "    \"\"\"\n",
    "    print(f\"Inspecting file: {file_path}\")\n",
    "    dataset = tf.data.TFRecordDataset(file_path)\n",
    "    \n",
    "    for i, raw_record in enumerate(dataset.take(num_examples)):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Protein {i+1}:\")\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "        \n",
    "        # Get protein ID\n",
    "        prot_id = example.features.feature['prot_id'].bytes_list.value[0].decode('utf-8')\n",
    "        print(f\"Protein ID: {prot_id}\")\n",
    "        \n",
    "        # Extract and print L value\n",
    "        if 'L' in example.features.feature:\n",
    "            L_value = list(example.features.feature['L'].int64_list.value)[0]\n",
    "            print(f\"\\nL (sequence length): {L_value}\")\n",
    "        \n",
    "        # Extract and analyze seq_1hot\n",
    "        if 'seq_1hot' in example.features.feature:\n",
    "            seq_1hot = list(example.features.feature['seq_1hot'].float_list.value)\n",
    "            seq_length = len(seq_1hot) // 20  # 20 amino acids per position\n",
    "            \n",
    "            print(f\"\\nseq_1hot analysis:\")\n",
    "            print(f\"  - Total values in seq_1hot: {len(seq_1hot)}\")\n",
    "            print(f\"  - Calculated sequence length: {seq_length}\")\n",
    "            print(f\"  - Expected total (seq_length * 20): {seq_length * 20}\")\n",
    "            \n",
    "            # Print first 10 positions of the sequence\n",
    "            print(f\"\\nFirst 10 amino acid positions:\")\n",
    "            amino_acids = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', \n",
    "                          'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
    "            \n",
    "            for pos in range(min(10, seq_length)):\n",
    "                pos_values = seq_1hot[pos*20:(pos+1)*20]\n",
    "                # Find which amino acid is encoded (should have value 1.0)\n",
    "                for aa_idx, val in enumerate(pos_values):\n",
    "                    if val == 1.0:\n",
    "                        print(f\"  Position {pos+1}: {amino_acids[aa_idx]} (index {aa_idx})\")\n",
    "                        break\n",
    "                else:\n",
    "                    print(f\"  Position {pos+1}: No amino acid found (all zeros)\")\n",
    "            \n",
    "            # Print some statistics about the one-hot encoding\n",
    "            total_ones = sum(1 for val in seq_1hot if val == 1.0)\n",
    "            total_zeros = sum(1 for val in seq_1hot if val == 0.0)\n",
    "            other_values = len(seq_1hot) - total_ones - total_zeros\n",
    "            \n",
    "            print(f\"\\nseq_1hot statistics:\")\n",
    "            print(f\"  - Total 1.0 values: {total_ones}\")\n",
    "            print(f\"  - Total 0.0 values: {total_zeros}\")\n",
    "            print(f\"  - Other values: {other_values}\")\n",
    "            \n",
    "            # Show a sample of the raw values (first 40 values = first 2 positions)\n",
    "            print(f\"\\nRaw seq_1hot values (first 40 = first 2 positions):\")\n",
    "            for i in range(0, min(40, len(seq_1hot)), 20):\n",
    "                position_vals = seq_1hot[i:i+20]\n",
    "                print(f\"  Position {i//20 + 1}: {position_vals}\")\n",
    "\n",
    "# Use the function\n",
    "train_file = \"PDB-GO/PDB_GO_train_00-of-30.tfrecords\"\n",
    "inspect_seq_and_L_values(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting file: PDB-GO/PDB_GO_train_00-of-30.tfrecords\n",
      "\n",
      "Protein 1:\n",
      "Protein ID: 2ZPA-A\n",
      "\n",
      "Feature shapes:\n",
      "  - prot_id: bytes, shape=1\n",
      "  - cb_dist_matrix: float, shape=450241\n",
      "  - mf_labels: int64, shape=489\n",
      "  - ca_dist_matrix: float, shape=450241\n",
      "  - cc_labels: int64, shape=320\n",
      "  - seq_1hot: float, shape=17446\n",
      "  - L: int64, shape=1\n",
      "  - bp_labels: int64, shape=1943\n",
      "\n",
      "Label analysis:\n",
      "\n",
      "Cellular Component (cc_labels):\n",
      "  - Total labels: 320\n",
      "  - Active labels (value=1): 0\n",
      "\n",
      "Molecular Function (mf_labels):\n",
      "  - Total labels: 489\n",
      "  - Active labels (value=1): 15\n",
      "  - Active indices: [9, 68, 74, 88, 98, 114, 183, 205, 253, 270, 337, 339, 463, 482, 488]\n",
      "\n",
      "Biological Process (bp_labels):\n",
      "  - Total labels: 1943\n",
      "  - Active labels (value=1): 10\n",
      "  - Active indices: [46, 136, 192, 273, 322, 623, 637, 781, 1221, 1417]\n",
      "\n",
      "Decoded sequence (L=671): AVMIXQACAKAZAAQGEAKTAVSAFAAAAIRAPWDNAMAILOHUBAGACAFAPAAATGAA…\n",
      "\n",
      "Protein 2:\n",
      "Protein ID: 2GBB-A\n",
      "\n",
      "Feature shapes:\n",
      "  - seq_1hot: float, shape=4056\n",
      "  - mf_labels: int64, shape=489\n",
      "  - L: int64, shape=1\n",
      "  - ca_dist_matrix: float, shape=24336\n",
      "  - cb_dist_matrix: float, shape=24336\n",
      "  - cc_labels: int64, shape=320\n",
      "  - bp_labels: int64, shape=1943\n",
      "  - prot_id: bytes, shape=1\n",
      "\n",
      "Label analysis:\n",
      "\n",
      "Cellular Component (cc_labels):\n",
      "  - Total labels: 320\n",
      "  - Active labels (value=1): 1\n",
      "  - Active indices: [81]\n",
      "\n",
      "Molecular Function (mf_labels):\n",
      "  - Total labels: 489\n",
      "  - Active labels (value=1): 2\n",
      "  - Active indices: [250, 432]\n",
      "\n",
      "Biological Process (bp_labels):\n",
      "  - Total labels: 1943\n",
      "  - Active labels (value=1): 15\n",
      "  - Active indices: [18, 155, 313, 314, 370, 546, 744, 792, 934, 1203, 1319, 1707, 1732, 1744, 1871]\n",
      "\n",
      "Decoded sequence (L=156): AELAMNJSAAAAAAIAGHAAACAADAAAAADAAYBPQACEKAUFAAAIAAZMAGRACFVH…\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "#  Add this helper just once, outside the loop\n",
    "AA_TABLE = \"ACDEFGHIKLMNPQRSTVWYXBZJUO\"   # 26-way alphabet\n",
    "AA_COLS  = len(AA_TABLE)                  # 26\n",
    "AA_COLS20 = 20                            # canonical set\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def inspect_protein_labels(file_path, num_examples=2):\n",
    "    \"\"\"\n",
    "    Inspects a protein record and its labels from a TFRecord file.\n",
    "    For each label type (cc, mf, bp), identifies which positions have a value of 1.\n",
    "    \"\"\"\n",
    "    print(f\"Inspecting file: {file_path}\")\n",
    "    dataset = tf.data.TFRecordDataset(file_path)\n",
    "    \n",
    "    for i, raw_record in enumerate(dataset.take(num_examples)):\n",
    "        print(f\"\\nProtein {i+1}:\")\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "        \n",
    "        # Get protein ID\n",
    "        prot_id = example.features.feature['prot_id'].bytes_list.value[0].decode('utf-8')\n",
    "        print(f\"Protein ID: {prot_id}\")\n",
    "        \n",
    "        # Print shape information for all features\n",
    "        print(\"\\nFeature shapes:\")\n",
    "        for key in example.features.feature:\n",
    "            feature = example.features.feature[key]\n",
    "            \n",
    "            if feature.HasField('bytes_list'):\n",
    "                shape = len(feature.bytes_list.value)\n",
    "                dtype = \"bytes\"\n",
    "            elif feature.HasField('float_list'):\n",
    "                shape = len(feature.float_list.value)\n",
    "                dtype = \"float\"\n",
    "            elif feature.HasField('int64_list'):\n",
    "                shape = len(feature.int64_list.value)\n",
    "                dtype = \"int64\"\n",
    "            \n",
    "            print(f\"  - {key}: {dtype}, shape={shape}\")\n",
    "        \n",
    "        # Extract and analyze label features\n",
    "        label_types = {\n",
    "            'cc_labels': 'Cellular Component',\n",
    "            'mf_labels': 'Molecular Function',\n",
    "            'bp_labels': 'Biological Process'\n",
    "        }\n",
    "        \n",
    "        print(\"\\nLabel analysis:\")\n",
    "        for label_key, label_name in label_types.items():\n",
    "            if label_key in example.features.feature:\n",
    "                labels = list(example.features.feature[label_key].int64_list.value)\n",
    "                active_indices = [i for i, val in enumerate(labels) if val == 1]\n",
    "                \n",
    "                print(f\"\\n{label_name} ({label_key}):\")\n",
    "                print(f\"  - Total labels: {len(labels)}\")\n",
    "                print(f\"  - Active labels (value=1): {len(active_indices)}\")\n",
    "                if len(active_indices) > 0:\n",
    "                    print(f\"  - Active indices: {active_indices}\")\n",
    "        \n",
    "        # ---------- NEW: decode and print amino-acid sequence ----------\n",
    "        if 'seq_1hot' in example.features.feature:\n",
    "            one_hot_flat = example.features.feature['seq_1hot'].float_list.value\n",
    "            \n",
    "            if len(one_hot_flat) % 26 == 0:\n",
    "                L = len(one_hot_flat) // 26\n",
    "                # NOTE the (26, L) shape  ↓  and that we take argmax over axis 0\n",
    "                one_hot = np.asarray(one_hot_flat, dtype=np.float32).reshape(26, L)\n",
    "                aa_idx  = one_hot.argmax(axis=0)          # length-L vector\n",
    "                sequence = ''.join(AA_TABLE[i] for i in aa_idx)\n",
    "                print(f\"\\nDecoded sequence (L={L}): {sequence[:60]}…\")\n",
    "            elif len(one_hot_flat) % 20 == 0:\n",
    "                L = len(one_hot_flat) // 20\n",
    "                one_hot = np.asarray(one_hot_flat, dtype=np.float32).reshape(20, L)\n",
    "                aa_idx  = one_hot.argmax(axis=0)\n",
    "                canon   = AA_TABLE[:20]                   # A-Y\n",
    "                sequence = ''.join(canon[i] for i in aa_idx)\n",
    "                print(f\"\\nDecoded 20-col sequence (L={L}): {sequence[:60]}…\")\n",
    "            else:\n",
    "                print(\"\\n⚠️ seq_1hot length not divisible by 20 or 26\")\n",
    "\n",
    "# Use proper file path with forward slashes\n",
    "train_file = \"PDB-GO/PDB_GO_train_00-of-30.tfrecords\"\n",
    "inspect_protein_labels(train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>GO TERMS</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0032559    adenyl ribonucleotide binding\n",
      "GO:0008080    N-acetyltransferase activity\n",
      "GO:0016746    transferase activity, transferring acyl groups\n",
      "GO:0017076    purine nucleotide binding\n",
      "GO:0005524    ATP binding\n",
      "GO:0035639    purine ribonucleoside triphosphate binding\n",
      "GO:0016410    N-acyltransferase activity\n",
      "GO:0016747    transferase activity, transferring acyl groups other than amino-acyl groups\n",
      "GO:0097367    carbohydrate derivative binding\n",
      "GO:0000049    tRNA binding\n",
      "GO:0032555    purine ribonucleotide binding\n",
      "GO:0030554    adenyl nucleotide binding\n",
      "GO:0003723    RNA binding\n",
      "GO:0016407    acetyltransferase activity\n",
      "GO:0032553    ribonucleotide binding\n"
     ]
    }
   ],
   "source": [
    "import json, pathlib, tensorflow as tf\n",
    "\n",
    "# path to the JSON that matches the ontology you are decoding\n",
    "PARAMS = pathlib.Path(\n",
    "r\"C:\\Users\\rfrjo\\Documents\\Codebases\\PFP_TESTING\\trained_models\\DeepFRI-MERGED_MultiGraphConv_3x512_fcd_1024_ca_10A_molecular_function_model_params.json\")\n",
    "\n",
    "with PARAMS.open() as fh:\n",
    "    vocab = json.load(fh)\n",
    "\n",
    "MF_IDS   = vocab[\"goterms\"]   # ['GO:0000166', 'GO:0000287', …]  length 489\n",
    "MF_NAMES = vocab[\"gonames\"]   # ['nucleotide binding', 'magnesium-ion binding', …]\n",
    "\n",
    "active_idx = [9, 68, 74, 88, 98, 114, 183, 205, 253, 270, 337, 339, 463, 482, 488]       # from your print-out\n",
    "\n",
    "active_go  = [MF_IDS[i]   for i in active_idx]       # GO IDs\n",
    "active_txt = [MF_NAMES[i] for i in active_idx]       # English names\n",
    "\n",
    "for go_id, name in zip(active_go, active_txt):\n",
    "    print(f\"{go_id:<12}  {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pathlib, tensorflow as tf\n",
    "\n",
    "# path to the JSON that matches the ontology you are decoding\n",
    "PARAMS = pathlib.Path(\n",
    "r\"C:\\Users\\rfrjo\\Documents\\Codebases\\PFP_Testing\\trained_models\\DeepCNN-MERGED_cellular_component_model_params.json\")\n",
    "\n",
    "with PARAMS.open() as fh:\n",
    "    vocab = json.load(fh)\n",
    "\n",
    "CC_IDS   = vocab[\"goterms\"]   # ['GO:0000166', 'GO:0000287', …]  length 489\n",
    "CC_NAMES = vocab[\"gonames\"]   # ['nucleotide binding', 'magnesium-ion binding', …]\n",
    "\n",
    "active_idx = []      # from your print-out\n",
    "\n",
    "active_go  = [CC_IDS[i]   for i in active_idx]       # GO IDs\n",
    "active_txt = [CC_NAMES[i] for i in active_idx]       # English names\n",
    "\n",
    "for go_id, name in zip(active_go, active_txt):\n",
    "    print(f\"{go_id:<12}  {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0008033    tRNA processing\n",
      "GO:0006399    tRNA metabolic process\n",
      "GO:0034660    ncRNA metabolic process\n",
      "GO:0002097    tRNA wobble base modification\n",
      "GO:0016070    RNA metabolic process\n",
      "GO:0043412    macromolecule modification\n",
      "GO:0006396    RNA processing\n",
      "GO:0034470    ncRNA processing\n",
      "GO:0006400    tRNA modification\n",
      "GO:0009451    RNA modification\n"
     ]
    }
   ],
   "source": [
    "import json, pathlib, tensorflow as tf\n",
    "\n",
    "# path to the JSON that matches the ontology you are decoding\n",
    "PARAMS = pathlib.Path(\n",
    "r\"C:\\Users\\rfrjo\\Documents\\Codebases\\PFP_Testing\\trained_models\\DeepCNN-MERGED_biological_process_model_params.json\")\n",
    "\n",
    "with PARAMS.open() as fh:\n",
    "    vocab = json.load(fh)\n",
    "\n",
    "BP_IDS   = vocab[\"goterms\"]   # ['GO:0000166', 'GO:0000287', …]  length 489\n",
    "BP_NAMES = vocab[\"gonames\"]   # ['nucleotide binding', 'magnesium-ion binding', …]\n",
    "\n",
    "active_idx = [46, 136, 192, 273, 322, 623, 637, 781, 1221, 1417] # from your print-out\n",
    "\n",
    "active_go  = [BP_IDS[i]   for i in active_idx]       # GO IDs\n",
    "active_txt = [BP_NAMES[i] for i in active_idx]       # English names\n",
    "\n",
    "for go_id, name in zip(active_go, active_txt):\n",
    "    print(f\"{go_id:<12}  {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PROTEIN SEQUENCE COVERAGE ANALYSIS\n",
      "======================================================================\n",
      "Parsing FASTA file: C:\\Users\\rfrjo\\Documents\\Codebases\\PFP_Testing\\nrPDB-GO_2019.06.18_sequences.fasta\n",
      "Found 36641 protein sequences in FASTA file\n",
      "\n",
      "Scanning protein data directory: protein_data_pdb\n",
      "Found 29740 proteins in structure data\n",
      "\n",
      "======================================================================\n",
      "COVERAGE ANALYSIS RESULTS\n",
      "======================================================================\n",
      "Structure proteins with sequences: 29740\n",
      "Structure proteins missing sequences: 0\n",
      "Extra sequences (not in structure data): 6901\n",
      "\n",
      "COVERAGE PERCENTAGE: 100.00%\n",
      "\n",
      "Detailed Breakdown:\n",
      "  • Total proteins in structure data: 29740\n",
      "  • Total sequences in FASTA: 36641\n",
      "  • Proteins with both structure & sequence: 29740\n",
      "  • Proteins with structure but no sequence: 0\n",
      "  • Sequences without structure data: 6901\n",
      "\n",
      "Sample sequences without structure data (showing first 10):\n",
      "  1. 11AS-A\n",
      "  2. 18GS-A\n",
      "  3. 192L-A\n",
      "  4. 1A0A-A\n",
      "  5. 1A0P-A\n",
      "  6. 1A21-A\n",
      "  7. 1A22-A\n",
      "  8. 1A27-A\n",
      "  9. 1A3Q-A\n",
      "  10. 1A44-A\n",
      "  ... and 6891 more\n",
      "\n",
      "Sample successful matches (showing first 10):\n",
      "  1. 154L-A\n",
      "  2. 155C-A\n",
      "  3. 16PK-A\n",
      "  4. 16VP-A\n",
      "  5. 1914-A\n",
      "  6. 19HC-A\n",
      "  7. 1A05-A\n",
      "  8. 1A0C-A\n",
      "  9. 1A0D-A\n",
      "  10. 1A0E-A\n",
      "  ... and 29730 more\n",
      "\n",
      "======================================================================\n",
      "ANALYSIS COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Verifying sample protein data structure:\n",
      "--------------------------------------------------\n",
      "154L-A: 6 files (bp_labels.pt, ca_dist_matrix.pt, cb_dist_matrix.pt, cc_labels.pt, L.csv, mf_labels.pt)\n",
      "155C-A: 6 files (bp_labels.pt, ca_dist_matrix.pt, cb_dist_matrix.pt, cc_labels.pt, L.csv, mf_labels.pt)\n",
      "16PK-A: 6 files (bp_labels.pt, ca_dist_matrix.pt, cb_dist_matrix.pt, cc_labels.pt, L.csv, mf_labels.pt)\n",
      "16VP-A: 6 files (bp_labels.pt, ca_dist_matrix.pt, cb_dist_matrix.pt, cc_labels.pt, L.csv, mf_labels.pt)\n",
      "1914-A: 6 files (bp_labels.pt, ca_dist_matrix.pt, cb_dist_matrix.pt, cc_labels.pt, L.csv, mf_labels.pt)\n",
      "\n",
      "Script completed successfully!\n",
      "Coverage Summary: 100.0% of structure proteins have sequences\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def parse_fasta_protein_ids(fasta_path):\n",
    "    \"\"\"\n",
    "    Parse FASTA file and extract protein IDs.\n",
    "    Expected format: >{protein_id} nrPDB\n",
    "    \"\"\"\n",
    "    protein_ids = set()\n",
    "    \n",
    "    try:\n",
    "        with open(fasta_path, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line.startswith('>'):\n",
    "                    # Extract protein ID from header line\n",
    "                    # Format: >{protein_id} nrPDB\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 1:\n",
    "                        protein_id = parts[0][1:]  # Remove the '>' character\n",
    "                        protein_ids.add(protein_id)\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: FASTA file not found at {fasta_path}\")\n",
    "        return set()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading FASTA file: {e}\")\n",
    "        return set()\n",
    "    \n",
    "    return protein_ids\n",
    "\n",
    "def get_protein_data_ids(protein_data_dir):\n",
    "    \"\"\"\n",
    "    Get all protein IDs from the protein_data_pdb directory structure.\n",
    "    \"\"\"\n",
    "    protein_ids = set()\n",
    "    \n",
    "    if not os.path.exists(protein_data_dir):\n",
    "        print(f\"Error: Protein data directory not found at {protein_data_dir}\")\n",
    "        return set()\n",
    "    \n",
    "    try:\n",
    "        for item in os.listdir(protein_data_dir):\n",
    "            item_path = os.path.join(protein_data_dir, item)\n",
    "            if os.path.isdir(item_path):\n",
    "                protein_ids.add(item)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading protein data directory: {e}\")\n",
    "        return set()\n",
    "    \n",
    "    return protein_ids\n",
    "\n",
    "def analyze_sequence_coverage():\n",
    "    \"\"\"\n",
    "    Main function to analyze coverage between protein structure data and FASTA sequences.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuration\n",
    "    fasta_path = r\"C:\\Users\\rfrjo\\Documents\\Codebases\\PFP_Testing\\nrPDB-GO_2019.06.18_sequences.fasta\"\n",
    "    protein_data_dir = \"protein_data_pdb\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"PROTEIN SEQUENCE COVERAGE ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Parse FASTA file for protein IDs\n",
    "    print(f\"Parsing FASTA file: {fasta_path}\")\n",
    "    fasta_protein_ids = parse_fasta_protein_ids(fasta_path)\n",
    "    print(f\"Found {len(fasta_protein_ids)} protein sequences in FASTA file\")\n",
    "    \n",
    "    # Get protein IDs from structure data\n",
    "    print(f\"\\nScanning protein data directory: {protein_data_dir}\")\n",
    "    structure_protein_ids = get_protein_data_ids(protein_data_dir)\n",
    "    print(f\"Found {len(structure_protein_ids)} proteins in structure data\")\n",
    "    \n",
    "    if len(fasta_protein_ids) == 0 or len(structure_protein_ids) == 0:\n",
    "        print(\"Error: Could not load protein data. Please check file paths.\")\n",
    "        return\n",
    "    \n",
    "    # Find matches and mismatches\n",
    "    matching_proteins = structure_protein_ids.intersection(fasta_protein_ids)\n",
    "    missing_sequences = structure_protein_ids - fasta_protein_ids\n",
    "    extra_sequences = fasta_protein_ids - structure_protein_ids\n",
    "    \n",
    "    # Calculate coverage statistics\n",
    "    coverage_percentage = (len(matching_proteins) / len(structure_protein_ids)) * 100\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"COVERAGE ANALYSIS RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"Structure proteins with sequences: {len(matching_proteins)}\")\n",
    "    print(f\"Structure proteins missing sequences: {len(missing_sequences)}\")\n",
    "    print(f\"Extra sequences (not in structure data): {len(extra_sequences)}\")\n",
    "    print(f\"\\nCOVERAGE PERCENTAGE: {coverage_percentage:.2f}%\")\n",
    "    \n",
    "    # Detailed breakdown\n",
    "    print(f\"\\nDetailed Breakdown:\")\n",
    "    print(f\"  • Total proteins in structure data: {len(structure_protein_ids)}\")\n",
    "    print(f\"  • Total sequences in FASTA: {len(fasta_protein_ids)}\")\n",
    "    print(f\"  • Proteins with both structure & sequence: {len(matching_proteins)}\")\n",
    "    print(f\"  • Proteins with structure but no sequence: {len(missing_sequences)}\")\n",
    "    print(f\"  • Sequences without structure data: {len(extra_sequences)}\")\n",
    "    \n",
    "    # Show some examples if there are missing sequences\n",
    "    if len(missing_sequences) > 0:\n",
    "        print(f\"\\nSample proteins missing sequences (showing first 10):\")\n",
    "        sample_missing = sorted(list(missing_sequences))[:10]\n",
    "        for i, protein_id in enumerate(sample_missing, 1):\n",
    "            print(f\"  {i}. {protein_id}\")\n",
    "        if len(missing_sequences) > 10:\n",
    "            print(f\"  ... and {len(missing_sequences) - 10} more\")\n",
    "    \n",
    "    # Show some examples of extra sequences\n",
    "    if len(extra_sequences) > 0:\n",
    "        print(f\"\\nSample sequences without structure data (showing first 10):\")\n",
    "        sample_extra = sorted(list(extra_sequences))[:10]\n",
    "        for i, protein_id in enumerate(sample_extra, 1):\n",
    "            print(f\"  {i}. {protein_id}\")\n",
    "        if len(extra_sequences) > 10:\n",
    "            print(f\"  ... and {len(extra_sequences) - 10} more\")\n",
    "    \n",
    "    # Show some examples of successful matches\n",
    "    if len(matching_proteins) > 0:\n",
    "        print(f\"\\nSample successful matches (showing first 10):\")\n",
    "        sample_matches = sorted(list(matching_proteins))[:10]\n",
    "        for i, protein_id in enumerate(sample_matches, 1):\n",
    "            print(f\"  {i}. {protein_id}\")\n",
    "        if len(matching_proteins) > 10:\n",
    "            print(f\"  ... and {len(matching_proteins) - 10} more\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Return results for potential further use\n",
    "    return {\n",
    "        'total_structure_proteins': len(structure_protein_ids),\n",
    "        'total_fasta_sequences': len(fasta_protein_ids),\n",
    "        'matching_proteins': len(matching_proteins),\n",
    "        'missing_sequences': len(missing_sequences),\n",
    "        'extra_sequences': len(extra_sequences),\n",
    "        'coverage_percentage': coverage_percentage,\n",
    "        'matching_protein_ids': matching_proteins,\n",
    "        'missing_sequence_ids': missing_sequences,\n",
    "        'extra_sequence_ids': extra_sequences\n",
    "    }\n",
    "\n",
    "def verify_sample_proteins(sample_size=5):\n",
    "    \"\"\"\n",
    "    Verify a few sample proteins by checking their structure data files.\n",
    "    \"\"\"\n",
    "    protein_data_dir = \"protein_data_pdb\"\n",
    "    \n",
    "    if not os.path.exists(protein_data_dir):\n",
    "        print(f\"Protein data directory not found: {protein_data_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nVerifying sample protein data structure:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Get a few sample proteins\n",
    "    protein_dirs = [d for d in os.listdir(protein_data_dir) \n",
    "                   if os.path.isdir(os.path.join(protein_data_dir, d))]\n",
    "    \n",
    "    sample_proteins = protein_dirs[:sample_size]\n",
    "    \n",
    "    for protein_id in sample_proteins:\n",
    "        protein_path = os.path.join(protein_data_dir, protein_id)\n",
    "        files = os.listdir(protein_path)\n",
    "        print(f\"{protein_id}: {len(files)} files ({', '.join(files)})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the coverage analysis\n",
    "    results = analyze_sequence_coverage()\n",
    "    \n",
    "    # Verify sample protein structure\n",
    "    verify_sample_proteins()\n",
    "    \n",
    "    print(f\"\\nScript completed successfully!\")\n",
    "    if results:\n",
    "        print(f\"Coverage Summary: {results['coverage_percentage']:.1f}% of structure proteins have sequences\")\n",
    "#NOTE: VAL ALSO HAVE SEQUENCE COVERAGE AT 100%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
