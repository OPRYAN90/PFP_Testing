_target_: src.models.protein_module.ProteinLitModule

# Model architecture parameters
d_model: 640
d_msa: 768
n_seq_layers: 2
n_cross_layers: 2
n_heads: 8
dropout: 0.1
label_smoothing: 0.1  # Slightly higher for production robustness

# MSA Encoder specific dropout parameters (now exposed)
# p_row: 0.15      # Row dropout probability (individual sequences) - hardcoded in MSAEncoder
# p_chan: 0.15     # Channel dropout probability (AlphaFold-style) - hardcoded in MSAEncoder  
# p_feat: 0.10     # Feature dropout after projection - hardcoded in MSAEncoder

# Compilation setting (consistent naming)
debugging: false  # Production mode (enables torch.compile for speed)

# Optimizer configuration - more aggressive for production
optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 2e-4  # Slightly higher LR for production
  weight_decay: 1e-2
  betas: [0.9, 0.999]
  eps: 1e-8

# Scheduler configuration with warmup  
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  _partial_: true
  max_lr: 2e-4  
  total_steps: ${eval:'${trainer.max_epochs} * ${oc.env:STEPS_PER_EPOCH,100}'}  # Will be calculated
  pct_start: 0.1  # 10% warmup
  anneal_strategy: "cos"
  div_factor: 25.0
  final_div_factor: 1e4 